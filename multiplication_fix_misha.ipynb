{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LcjOGEs6t_K",
    "outputId": "e130937f-6466-4da0-b970-8b9a58e611d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tntorch\n",
      "  Downloading tntorch-1.1.1-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 3.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tntorch) (1.21.6)\n",
      "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.7/dist-packages (from tntorch) (1.12.1+cu113)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tntorch) (1.7.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.11->tntorch) (4.1.1)\n",
      "Installing collected packages: tntorch\n",
      "Successfully installed tntorch-1.1.1\n"
     ]
    }
   ],
   "source": [
    "pip install tntorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SNK-5eNf6jHp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import tntorch as tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s5640QU16jHq"
   },
   "outputs": [],
   "source": [
    "def tt_multiply(tt: tn.Tensor, tensor: torch.Tensor, shapes, in_dims):\n",
    "    \"\"\"\n",
    "    Multiply TTTensor by any tensor of more than 1-way.\n",
    "    For vectors, reshape them to matrix of shape 1 x I\n",
    "    \n",
    "    shapes: shapes of the intitial tensor be decomposed to\n",
    "    in_dims: factors of input dimentions of initial 2D matrix\n",
    "    over these dimensions, convolution is performed when multiplying\n",
    "    \n",
    "    returns: torch.Tensor of shape b x num_cols(tt_matrix)\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(tensor.shape) > 1\n",
    "    assert (tt.ranks_tt is not None) # be sure that tt tensor\n",
    "    assert  torch.prod(in_dims) == tensor.shape[1]\n",
    "\n",
    "    rows = torch.prod(in_dims)\n",
    "    b = tensor.reshape(-1, rows).shape[0]\n",
    "    tensor = tensor.reshape(b, -1).T\n",
    "    result = tensor.reshape(in_dims[0], -1)\n",
    "    core = tt.cores[0].reshape(tt.cores[0].shape[0], in_dims[0], -1, tt.cores[0].shape[2])\n",
    "    result = torch.einsum('id,lior->ldor', result, core)\n",
    "\n",
    "    for d in range(1, len(tt.cores)):\n",
    "        core = tt.cores[d].reshape(tt.cores[d].shape[0], in_dims[d], -1, tt.cores[d].shape[2])\n",
    "        result = result.reshape(in_dims[d], -1, core.shape[0])\n",
    "        result = torch.einsum('idr,riob->dob', result, core)\n",
    "\n",
    "    return result.reshape(b, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t32vvuwU6jHr"
   },
   "outputs": [],
   "source": [
    "def test_tt_multiply():\n",
    "    m = torch.rand(11 * 2, 23 * 3)\n",
    "    v = torch.rand(30, 11 * 2)  # Note: batch = 30, 11 * 3 features\n",
    "\n",
    "    input_dims = [11, 2]\n",
    "    output_dims = [23, 3]\n",
    "    ranks = [50]\n",
    "\n",
    "    tt = tn.Tensor(m.reshape(11, 2, 23, 3).permute(0, 2, 1, 3).reshape(11 * 23, 2 * 3), ranks_tt=[40])\n",
    "\n",
    "    a = tt.torch().reshape(11, 23, 2, 3).permute(0, 2, 1, 3).reshape(11 * 2, 23 * 3)\n",
    "\n",
    "    b = tt_multiply(tt, v, shapes = (11 * 3, 23 * 2), in_dims = torch.tensor([11, 2]))\n",
    "\n",
    "    assert torch.allclose((v @ a), b), f'error: {torch.norm((v @ a) -  b)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tt_multiply():\n",
    "    m = torch.rand(11 * 2, 23 * 3)\n",
    "    v = torch.rand(30, 11 * 2)  # Note: batch = 30, 11 * 3 features\n",
    "\n",
    "    input_dims = [11, 2]\n",
    "    output_dims = [23, 3]\n",
    "    ranks = [50]\n",
    "\n",
    "    tt = tn.Tensor(m.reshape(11, 2, 23, 3).permute(0, 2, 1, 3).reshape(11 * 23, 2 * 3), ranks_tt=[40])\n",
    "\n",
    "    a = tt.torch().reshape(11, 23, 2, 3).permute(0, 2, 1, 3).reshape(11 * 2, 23 * 3)\n",
    "\n",
    "    b = tt_multiply(tt, v, shapes = (11 * 3, 23 * 2), in_dims = torch.tensor([11, 2]))\n",
    "\n",
    "    assert torch.allclose((v @ a), b), f'error: {torch.norm((v @ a) -  b)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "giCytQoE6jHr"
   },
   "outputs": [],
   "source": [
    "def test_tt_multiply1():\n",
    "    v = torch.rand(30, 768)\n",
    "    m = torch.rand(768, 3072)\n",
    "    m_new = m.reshape(32, 48, 48, 32)\n",
    "    \n",
    "    in_dims = torch.tensor([4, 6, 8, 4])\n",
    "    out_dims = torch.tensor([8, 8, 6, 8])\n",
    "    \n",
    "    print (torch.allclose(m_new.permute(0, 2, 1, 3), m_new.permute(0, 2, 1, 3).permute(0, 1, 2, 3)))\n",
    "    print (torch.allclose(m, m_new.permute(0, 2, 1, 3).permute(0, 1, 2, 3).reshape(768, 3072)))\n",
    "    tt = tn.Tensor(m_new, ranks_tt=[30, 40, 50])\n",
    "    \n",
    "    for elem in tt.cores:\n",
    "        print (type(elem))\n",
    "        print (elem.shape)\n",
    "\n",
    "    restore = tt.torch()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.rand(30, 768)\n",
    "m = torch.rand(768, 3072)\n",
    "m_new = m.reshape(24, 32, 64, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_new = m.reshape(24, 32, 64, 48)\n",
    "tt = tn.Tensor(m_new, ranks_tt=[20, 30, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 32, 30])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([30, 48, 40])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([40, 48, 32])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([32, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "test_tt_multiply1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z8dVvK4x6jHr",
    "outputId": "9384ea39-270c-42dc-8658-0d2d9ac1d11d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 32, 3])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 48, 4])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([4, 48, 5])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([5, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "import tntorch as tn\n",
    "v = torch.rand(30, 768)\n",
    "m = torch.rand(768, 3072)\n",
    "m_new = m.reshape((32, 48, 48, 32))\n",
    "print (torch.allclose(m, m_new.reshape(768, 3072), atol=1e-05))\n",
    "tt = tn.Tensor(m_new, ranks_tt=[3, 4, 5])\n",
    "\n",
    "restore = tt.torch()\n",
    "\n",
    "print (torch.allclose(m, tt.torch().reshape((768, 3072)), atol=1e-01))\n",
    "\n",
    "for elem in tt.cores:\n",
    "    print (type(elem))\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HUxaU276jHr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZxmVRlh56jHs",
    "outputId": "80886249-0f4f-4d9e-c0ab-bb544746f147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([190.1586, 179.5659, 192.6148, 187.1103, 184.4869, 188.0385, 197.2183,\n",
       "        191.4984, 189.8160, 198.3449])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = v @ tt.torch().reshape((768, 3072))\n",
    "a[:10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4QPqBPx86jHs",
    "outputId": "c82808a6-0ffe-48a1-fd91-06199c3c8144"
   },
   "outputs": [],
   "source": [
    "res = tt_multiply(tt, v, shapes = (32, 48, 48, 32), in_dims = torch.tensor([4, 6, 8, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WWV1X77d6jHs",
    "outputId": "8e488fa1-3e76-4cc7-eb56-df3348e443e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([192.1574, 181.1985, 194.5892, 188.8939, 186.2896, 189.8886, 199.2628,\n",
       "        193.4445, 191.9202, 200.3451])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "anxwQEYf6jHs",
    "outputId": "99933b9e-4fc4-44d7-b5c7-17c03bf45cae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0066)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm((v @ tt.torch().reshape((768, 3072)))- res)/torch.norm(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ytnIDyCx6jHs",
    "outputId": "8b6f1dd2-56a8-4caa-887b-932d6d7dbc6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print (torch.allclose(v @ tt.torch().reshape(768, 3072), res, atol=1e-01))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwiB2X7H6jHs"
   },
   "source": [
    "## TTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r38u-85a6jHt"
   },
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.decomposition import tensor_train\n",
    "tl.set_backend('pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B45HbFgp6jHt"
   },
   "outputs": [],
   "source": [
    "v = torch.rand(30, 768)\n",
    "m = torch.rand(768, 3072)\n",
    "   \n",
    "input_dims = [4, 6, 8, 4]\n",
    "output_dims = [8, 8, 6, 8]\n",
    "ranks = [50, 50, 50]\n",
    "\n",
    "ttm = tn.TTMatrix(m, input_dims=input_dims, output_dims=output_dims, ranks=ranks)\n",
    "assert torch.allclose(v @ ttm.torch(), tn.tt_multiply(ttm, v))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiD-qn0Y6jHt",
    "outputId": "1a4b3992-1da2-4639-adf0-9300eb8cd9de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 32, 3])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 48, 4])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([4, 48, 5])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([5, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "for elem in tt.cores:\n",
    "    print (type(elem))\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UY3M_vVT6jHt",
    "outputId": "45c08f85-5c98-4116-bd61-b9c24b383027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 3072])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.rand(3072, 768) #8*4, 6*8, 6*8, 8*4\n",
    "v = torch.rand(30, 3072)  # Note: batch = 30, 11 * 3 features\n",
    "print ((v@m).shape)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akGo9ksq6jHt"
   },
   "outputs": [],
   "source": [
    "import tntorch as tn\n",
    "tt = tn.Tensor(m.reshape(32, 48, 48, 32), ranks_tt=[32, 36, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJiL9FhT6jHt"
   },
   "outputs": [],
   "source": [
    "tt_res = tt\n",
    "tt_res.cores = [torch.reshape(tt.cores[0],(1, 8, 4, 32)), torch.reshape(tt.cores[1], (32, 6, 8, 36)), torch.reshape(tt.cores[2], (36, 6, 8, 32)), torch.reshape(tt.cores[3], (32, 8, 4, 1))]\n",
    "\n",
    "input_dims = torch.tensor([8, 6, 6, 8])\n",
    "output_dims = torch.tensor([4, 8, 8, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTtDeL0g6jHu",
    "outputId": "e390e548-1df4-432a-c3b7-fef3ba7d0e22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 11520]) torch.Size([1, 8, 4, 32])\n",
      "result shape torch.Size([1, 11520, 4, 32])\n",
      "torch.Size([6, 7680, 32]) torch.Size([32, 6, 8, 36])\n",
      "result shape torch.Size([7680, 8, 36])\n",
      "torch.Size([8, 7680, 36]) torch.Size([36, 8, 6, 32])\n",
      "result shape torch.Size([7680, 6, 32])\n",
      "torch.Size([8, 5760, 32]) torch.Size([32, 8, 4, 1])\n",
      "result shape torch.Size([5760, 4, 1])\n",
      "torch.Size([30, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[758.3635, 757.5698, 762.0194,  ..., 760.6479, 753.1539, 758.3381],\n",
       "        [762.9049, 765.4019, 768.4266,  ..., 762.6346, 759.7394, 762.8599],\n",
       "        [785.9296, 786.1127, 789.0124,  ..., 786.3926, 781.9754, 783.9235],\n",
       "        ...,\n",
       "        [769.3828, 769.9366, 775.4473,  ..., 770.8221, 767.1511, 768.8950],\n",
       "        [772.4765, 774.3235, 780.9059,  ..., 773.8949, 769.3389, 773.3456],\n",
       "        [762.5847, 765.2134, 768.9113,  ..., 763.8503, 761.7515, 759.0067]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_multiply(ttm, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TDDXFgw6jHu"
   },
   "outputs": [],
   "source": [
    "def tt_multiply(tt_matrix: tn.TTMatrix, tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Multiply TTMatrix by any tensor of more than 1-way.\n",
    "    For vectors, reshape them to matrix of shape 1 x I\n",
    "    returns: torch.Tensor of shape b x num_cols(tt_matrix)\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(tensor.shape) > 1\n",
    "\n",
    "    rows = torch.prod(tt_matrix.input_dims)\n",
    "    b = tensor.reshape(-1, rows).shape[0]\n",
    "    tensor = tensor.reshape(b, -1).T\n",
    "    result = tensor.reshape(tt_matrix.input_dims[0], -1)\n",
    "    print (result.shape, tt_matrix.cores[0].shape)\n",
    "    result = torch.einsum('id,lior->ldor', result, tt_matrix.cores[0])\n",
    "    print (\"result shape\", result.shape)\n",
    "\n",
    "    for d in range(1, tt_matrix.d):\n",
    "        result = result.reshape(tt_matrix.input_dims[d], -1, tt_matrix.cores[d].shape[0])\n",
    "        print (result.shape, tt_matrix.cores[d].shape)\n",
    "        result = torch.einsum('idr,riob->dob', result, tt_matrix.cores[d])\n",
    "        print (\"result shape\", result.shape)\n",
    "    print (result.reshape(b, -1).shape)\n",
    "\n",
    "    return result.reshape(b, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O6Hyp8F6jHu"
   },
   "outputs": [],
   "source": [
    "fc_w_new.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOXWBwK26jHu"
   },
   "source": [
    "**singular values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "te_HWokN6jHu",
    "outputId": "fb97c522-009d-48e2-bccc-5f33573b9396"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvaPskXj6jHu",
    "outputId": "5588d44f-34c0-40b6-9535-6f5416210ace"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: (0, 2, 4, 1, 3, 5),\n",
       " 8: (0, 2, 4, 6, 1, 3, 5, 7),\n",
       " 10: (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{6:(0, 2, 4, 1, 3, 5), 8:(0, 2, 4, 6, 1, 3, 5, 7), 10:(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43j7QsC16jHu",
    "outputId": "4817b44b-60eb-436b-9115-d9c9dd002122"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5647360fad83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'input_' is not defined"
     ]
    }
   ],
   "source": [
    "a = colbert.bert.encoder.layer[4].intermediate.dense(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0Q88Cy06jHu",
    "outputId": "89dd5f0a-7368-48d2-fa08-b781e10ab700"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-22e123cdffcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_w_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'input_' is not defined"
     ]
    }
   ],
   "source": [
    "b = fc_w_new(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLCBnGg36jHu"
   },
   "outputs": [],
   "source": [
    "from tensorly.tt_matrix import TTMatrix\n",
    "\n",
    "perms = {6:(0, 2, 4, 1, 3, 5), 8:(0, 2, 4, 6, 1, 3, 5, 7), 10:(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)}\n",
    "\n",
    "for rank in [ 20, 30, 40, 50]:\n",
    "    m = colbert.bert.encoder.layer[4].intermediate.dense\n",
    "    input_ = torch.randn(batch_size, in_)\n",
    "    m_ttm = FactorizationTTMLinear(in_, out_, rank=rank, max_core_dim_product =rank)\n",
    "    m_ttm.fill_with_pretrained_matrix(fc_w)\n",
    "    restored_weight = TTMatrix([elem.data for elem in m_ttm.ttm.tt.cores]).to_tensor()\n",
    "    print (restored_weight.shape)\n",
    "    restored_weight = restored_weight.permute(perms[(len(restored_weight.shape))])\n",
    "    print (restored_weight.shape)\n",
    "    print (torch.norm(fc_w_new.weight - restored_weight.reshape(fc_w_new.weight.shape))/torch.norm(fc_w_new.weight))\n",
    "    print (restored_weight.shape)\n",
    "    c = m_ttm(input_)\n",
    "    print (torch.norm(a-c)/torch.norm(a))\n",
    "    print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JSSMtBa6jHv",
    "outputId": "bef80f0b-2a97-4315-ea9c-0e4847b06ea8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(771.9188, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(a-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omBNudjY6jHv",
    "outputId": "048349fc-e501-4762-b008-bbf2e48edb61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypt-7e_Z6jHw",
    "outputId": "74c226f7-e4cd-4e35-a532-5f736a0024aa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor_train_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-993f0028478e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_train_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor_train_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "factors = tensor_train_matrix(B, rank = [1, 60, 90, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRR5d6vv6jHw",
    "outputId": "8a9bfc95-a995-48f6-88b3-0ce4dbe52bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 16, 60])\n",
      "torch.Size([60, 12, 12, 90])\n",
      "torch.Size([90, 8, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "for elem in factors.factors:\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVTNNWaE6jHw",
    "outputId": "d2cd7f32-4e64-4ee7-b245-3e9028c3a004"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 12, 8, 12, 16])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_B = factors.to_tensor()\n",
    "new_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPO9hqEP6jHw",
    "outputId": "69d70c4d-b63b-4ec2-f6f4-8944a8ebad82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 12, 8, 12, 16])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBDN3UuX6jHw",
    "outputId": "7977f54f-518f-49b9-d96a-b462967e3f6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70110387"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(new_B - B)/np.linalg.norm(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXatxITj6jHw",
    "outputId": "10e79054-29b5-44f7-ac0c-34517b0aeac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 8, 60])\n",
      "torch.Size([60, 16, 12, 90])\n",
      "torch.Size([90, 12, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "for elem in factors:\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLNvxiJS6jHw",
    "outputId": "47e3e748-74ab-4626-f03a-5e85df4e15ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 3072)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_w.shape[1],fc_w.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWvSwxpK6jHw"
   },
   "outputs": [],
   "source": [
    "from src.ttm_linear.ttm_linear.ttm_linear import FactorizationTTMLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdcnnP2S6jHw",
    "outputId": "3d1745cf-c13b-491a-c53c-376d50707a81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 48, 48, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0wKGKek6jHw"
   },
   "outputs": [],
   "source": [
    "errs2 = []\n",
    "ranks2 = []\n",
    "c_rates2 = []\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tensor_train\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "\n",
    "B = fc_w\n",
    "B = B.reshape((32, 48, 48, 32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "err = 10.0\n",
    "rank1 = 5\n",
    "rank2 = 5\n",
    "step = 10\n",
    "compression_rate = 0.0\n",
    "while (compression_rate < 0.7):\n",
    "    factors = tensor_train(B, rank = [1, rank1, rank2, rank1, 1])\n",
    "    new_B = factors.to_tensor()\n",
    "    err = np.linalg.norm(new_B.detach().numpy() - B.detach().numpy())/np.linalg.norm(B.detach().numpy())\n",
    "    print ([elem.shape for elem in factors.factors])\n",
    "    compression_rate = (np.sum(list(np.prod(elem.shape) for elem in factors.factors))/(np.prod(fc_w.shape)))\n",
    "    print (\"err \", err, \"compression_rate \", compression_rate, \"rank \", rank1, rank2)\n",
    "    errs2.append(err)\n",
    "    ranks2.append(rank1)\n",
    "    c_rates2.append(compression_rate)\n",
    "    if (rank1 < rank2):\n",
    "        rank1 += step\n",
    "    else:\n",
    "        rank2 += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPHvtnXA6jHx",
    "outputId": "77df3a26-6bf6-4a2a-a95e-bed7d156ab61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 128, 5]), torch.Size([5, 144, 5]), torch.Size([5, 128, 1])]\n",
      "err  0.9830911 compression_rate  0.002068413628472222 rank  5 5\n",
      "[torch.Size([1, 128, 5]), torch.Size([5, 144, 15]), torch.Size([15, 128, 1])]\n",
      "err  0.97657156 compression_rate  0.005662706163194444 rank  5 15\n",
      "[torch.Size([1, 128, 15]), torch.Size([15, 144, 15]), torch.Size([15, 128, 1])]\n",
      "err  0.9700918 compression_rate  0.015360514322916666 rank  15 15\n",
      "[torch.Size([1, 128, 15]), torch.Size([15, 144, 25]), torch.Size([25, 128, 1])]\n",
      "err  0.96239424 compression_rate  0.025058322482638888 rank  15 25\n",
      "[torch.Size([1, 128, 25]), torch.Size([25, 144, 25]), torch.Size([25, 128, 1])]\n",
      "err  0.9518059 compression_rate  0.04085964626736111 rank  25 25\n",
      "[torch.Size([1, 128, 25]), torch.Size([25, 144, 35]), torch.Size([35, 128, 1])]\n",
      "err  0.94061637 compression_rate  0.056660970052083336 rank  25 35\n",
      "[torch.Size([1, 128, 35]), torch.Size([35, 144, 35]), torch.Size([35, 128, 1])]\n",
      "err  0.92628205 compression_rate  0.07856580946180555 rank  35 35\n",
      "[torch.Size([1, 128, 35]), torch.Size([35, 144, 45]), torch.Size([45, 128, 1])]\n",
      "err  0.91174954 compression_rate  0.10047064887152778 rank  35 45\n",
      "[torch.Size([1, 128, 45]), torch.Size([45, 144, 45]), torch.Size([45, 128, 1])]\n",
      "err  0.89364284 compression_rate  0.12847900390625 rank  45 45\n",
      "[torch.Size([1, 128, 45]), torch.Size([45, 144, 55]), torch.Size([55, 128, 1])]\n",
      "err  0.8757278 compression_rate  0.1564873589409722 rank  45 55\n",
      "[torch.Size([1, 128, 55]), torch.Size([55, 144, 55]), torch.Size([55, 128, 1])]\n",
      "err  0.8540543 compression_rate  0.19059922960069445 rank  55 55\n",
      "[torch.Size([1, 128, 55]), torch.Size([55, 144, 65]), torch.Size([65, 128, 1])]\n",
      "err  0.832709 compression_rate  0.22471110026041666 rank  55 65\n",
      "[torch.Size([1, 128, 65]), torch.Size([65, 144, 65]), torch.Size([65, 128, 1])]\n",
      "err  0.8069761 compression_rate  0.2649264865451389 rank  65 65\n",
      "[torch.Size([1, 128, 65]), torch.Size([65, 144, 75]), torch.Size([75, 128, 1])]\n",
      "err  0.7816111 compression_rate  0.3051418728298611 rank  65 75\n",
      "[torch.Size([1, 128, 75]), torch.Size([75, 144, 75]), torch.Size([75, 128, 1])]\n",
      "err  0.7513101 compression_rate  0.3514607747395833 rank  75 75\n",
      "[torch.Size([1, 128, 75]), torch.Size([75, 144, 85]), torch.Size([85, 128, 1])]\n",
      "err  0.72151625 compression_rate  0.3977796766493056 rank  75 85\n",
      "[torch.Size([1, 128, 85]), torch.Size([85, 144, 85]), torch.Size([85, 128, 1])]\n",
      "err  0.6855759 compression_rate  0.4502020941840278 rank  85 85\n",
      "[torch.Size([1, 128, 85]), torch.Size([85, 144, 95]), torch.Size([95, 128, 1])]\n",
      "err  0.6503146 compression_rate  0.50262451171875 rank  85 95\n",
      "[torch.Size([1, 128, 95]), torch.Size([95, 144, 95]), torch.Size([95, 128, 1])]\n",
      "err  0.60742176 compression_rate  0.5611504448784722 rank  95 95\n",
      "[torch.Size([1, 128, 95]), torch.Size([95, 144, 105]), torch.Size([105, 128, 1])]\n",
      "err  0.5646886 compression_rate  0.6196763780381944 rank  95 105\n",
      "[torch.Size([1, 128, 105]), torch.Size([105, 144, 105]), torch.Size([105, 128, 1])]\n",
      "err  0.51182956 compression_rate  0.6843058268229166 rank  105 105\n",
      "[torch.Size([1, 128, 105]), torch.Size([105, 144, 115]), torch.Size([115, 128, 1])]\n",
      "err  0.45775306 compression_rate  0.7489352756076388 rank  105 115\n"
     ]
    }
   ],
   "source": [
    "errs3 = []\n",
    "ranks3 = []\n",
    "c_rates3 = []\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tensor_train\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "\n",
    "B = fc_w\n",
    "B = B.reshape(128, 144, 128)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "err = 10.0\n",
    "rank1 = 5\n",
    "rank2 = 5\n",
    "step = 10\n",
    "compression_rate = 0.0\n",
    "while (compression_rate < 0.7):\n",
    "    factors = tensor_train(B, rank = [1, rank1, rank2, 1])\n",
    "    new_B = factors.to_tensor()\n",
    "    err = np.linalg.norm(new_B.detach().numpy() - B.detach().numpy())/np.linalg.norm(B.detach().numpy())\n",
    "    print ([elem.shape for elem in factors.factors])\n",
    "    compression_rate = (np.sum(list(np.prod(elem.shape) for elem in factors.factors))/(np.prod(fc_w.shape)))\n",
    "    print (\"err \", err, \"compression_rate \", compression_rate, \"rank \", rank1, rank2)\n",
    "    errs3.append(err)\n",
    "    ranks3.append(rank1)\n",
    "    c_rates3.append(compression_rate)\n",
    "    if (rank1 < rank2):\n",
    "        rank1 += step\n",
    "    else:\n",
    "        rank2 += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9M-1H8j6jHx",
    "outputId": "d58a5cf1-1873-43cc-cccb-64d949e2c22b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c_rates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_180/2976066177.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SVD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_rates3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrs3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TT 3 cores, 128*144*128 \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_rates3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrs3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TT 4 cores, 32*48*48*32 \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c_rates' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "\n",
    "# plot lines\n",
    "plt.plot(c_rates, errs, label = \"SVD\")\n",
    "plt.plot(c_rates3, errs3,  label = \"TT 3 cores, 128*144*128 \")\n",
    "plt.plot(c_rates3, errs3,  label = \"TT 4 cores, 32*48*48*32 \")\n",
    "plt.plot(c_rates1, errs1,  label = \"TT 6 cores, 8*12*16*16*12*8\")\n",
    "#plt.plot(errs1_m, c_rates1_m, label = \"TTM (permute + reshape)\")\n",
    "plt.ylabel('errors')\n",
    "plt.xlabel('compression rate')\n",
    "plt.legend()\n",
    "plt.savefig(\"TT + SVD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZ6Tv3C86jHx",
    "outputId": "a66fd3ab-ce00-4248-8035-befb903dee87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 335]), torch.Size([335, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5942937 compression_rate  0.4440646701388889 rank  335 335\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 345]), torch.Size([345, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5857147 compression_rate  0.4570855034722222 rank  335 345\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 345]), torch.Size([345, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5857147 compression_rate  0.4570855034722222 rank  345 345\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 355]), torch.Size([355, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5772192 compression_rate  0.4701063368055556 rank  345 355\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 355]), torch.Size([355, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5772191 compression_rate  0.4701063368055556 rank  355 355\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 365]), torch.Size([365, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5688087 compression_rate  0.4831271701388889 rank  355 365\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 365]), torch.Size([365, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5688087 compression_rate  0.4831271701388889 rank  365 365\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 375]), torch.Size([375, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.56046605 compression_rate  0.4961480034722222 rank  365 375\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 375]), torch.Size([375, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5604661 compression_rate  0.4961480034722222 rank  375 375\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 385]), torch.Size([385, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5522069 compression_rate  0.5091688368055556 rank  375 385\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 385]), torch.Size([385, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5522069 compression_rate  0.5091688368055556 rank  385 385\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 395]), torch.Size([395, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5440476 compression_rate  0.5221896701388888 rank  385 395\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 395]), torch.Size([395, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.54404753 compression_rate  0.5221896701388888 rank  395 395\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 405]), torch.Size([405, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5359411 compression_rate  0.5352105034722222 rank  395 405\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 405]), torch.Size([405, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.53594106 compression_rate  0.5352105034722222 rank  405 405\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 415]), torch.Size([415, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5279132 compression_rate  0.5482313368055556 rank  405 415\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 415]), torch.Size([415, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5279132 compression_rate  0.5482313368055556 rank  415 415\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 425]), torch.Size([425, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.51994663 compression_rate  0.5612521701388888 rank  415 425\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 425]), torch.Size([425, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.51994663 compression_rate  0.5612521701388888 rank  425 425\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 435]), torch.Size([435, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.51204914 compression_rate  0.5742730034722222 rank  425 435\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 435]), torch.Size([435, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.512049 compression_rate  0.5742730034722222 rank  435 435\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 445]), torch.Size([445, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.50423944 compression_rate  0.5872938368055556 rank  435 445\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 445]), torch.Size([445, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.50423944 compression_rate  0.5872938368055556 rank  445 445\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 455]), torch.Size([455, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.49648055 compression_rate  0.6003146701388888 rank  445 455\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 455]), torch.Size([455, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.49648046 compression_rate  0.6003146701388888 rank  455 455\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 465]), torch.Size([465, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.48879352 compression_rate  0.6133355034722222 rank  455 465\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 465]), torch.Size([465, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.48879352 compression_rate  0.6133355034722222 rank  465 465\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 475]), torch.Size([475, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.48117173 compression_rate  0.6263563368055556 rank  465 475\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 475]), torch.Size([475, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.4811717 compression_rate  0.6263563368055556 rank  475 475\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 485]), torch.Size([485, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.4736112 compression_rate  0.6393771701388888 rank  475 485\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 485]), torch.Size([485, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.47361115 compression_rate  0.6393771701388888 rank  485 485\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 495]), torch.Size([495, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.4661179 compression_rate  0.6523980034722222 rank  485 495\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 495]), torch.Size([495, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.46611792 compression_rate  0.6523980034722222 rank  495 495\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 505]), torch.Size([505, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.45867184 compression_rate  0.6654188368055556 rank  495 505\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 505]), torch.Size([505, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.45867184 compression_rate  0.6654188368055556 rank  505 505\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 515]), torch.Size([515, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.45130017 compression_rate  0.6784396701388888 rank  505 515\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 515]), torch.Size([515, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.45130017 compression_rate  0.6784396701388888 rank  515 515\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 525]), torch.Size([525, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.44399664 compression_rate  0.6914605034722222 rank  515 525\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 525]), torch.Size([525, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.4439966 compression_rate  0.6914605034722222 rank  525 525\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 535]), torch.Size([535, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.4367761 compression_rate  0.7044813368055556 rank  525 535\n"
     ]
    }
   ],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.decomposition import tensor_train\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "errs1 = []\n",
    "ranks1 = []\n",
    "c_rates1 = []\n",
    "\n",
    "B = fc_w\n",
    "B = B.reshape(8, 12, 16, 16, 12, 8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "err = 10.0\n",
    "rank1 = 5\n",
    "rank2 = 5\n",
    "step = 10\n",
    "compression_rate = 0.0\n",
    "while (compression_rate < 0.7):\n",
    "    factors = tensor_train(B, rank = [1, rank1, rank2, rank2, rank2, rank1, 1])\n",
    "    new_B = factors.to_tensor()\n",
    "    err = np.linalg.norm(new_B.detach().numpy() - B.detach().numpy())/np.linalg.norm(B.detach().numpy())\n",
    "    print ([elem.shape for elem in factors.factors])\n",
    "    compression_rate = (np.sum(list(np.prod(elem.shape) for elem in factors.factors))/(np.prod(fc_w.shape)))\n",
    "    print (\"err \", err, \"compression_rate \", compression_rate, \"rank \", rank1, rank2)\n",
    "    errs1.append(err)\n",
    "    ranks1.append(rank1)\n",
    "    c_rates1.append(compression_rate)\n",
    "    if (rank1 < rank2):\n",
    "        rank1 += step\n",
    "    else:\n",
    "        rank2 += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXHtLgXK6jHx"
   },
   "outputs": [],
   "source": [
    "B = fc_w\n",
    "B = B.reshape((32, 48, 48, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgRcufH26jHx",
    "outputId": "6e54eaee-2dfd-40b4-9707-32d7c07412ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359296"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(fc_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDFw1xhK6jHx",
    "outputId": "9c26067d-000b-4b1d-94bf-b1e17a52c69a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81661785"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_rest = tl.tt_tensor.tt_to_tensor(factors)\n",
    "err = np.linalg.norm(D_rest - D)/np.linalg.norm(D)\n",
    "err"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
