{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from colbert.modeling.colbert import ColBERT\n",
    "from colbert.utils.utils import print_message\n",
    "from colbert.training.utils import print_progress, manage_checkpoints\n",
    "\n",
    "query_maxlen = 512\n",
    "query_maxlen = 512\n",
    "doc_maxlen = 512\n",
    "dim = 128\n",
    "similarity = 'cosine'\n",
    "\n",
    "colbert = ColBERT.from_pretrained('bert-base-uncased', query_maxlen=query_maxlen, doc_maxlen=doc_maxlen, dim=dim, similarity_metric=similarity, mask_punctuation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_net1 import TTLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109580544\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in colbert.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2359296\n"
     ]
    }
   ],
   "source": [
    "fc_w = colbert.bert.encoder.layer[3].intermediate.dense\n",
    "fc_b = colbert.bert.encoder.layer[3].intermediate.dense.bias\n",
    "print(sum(p.numel() for p in fc_w.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in fc_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072 768\n",
      "layer.shape torch.Size([3072, 768])\n",
      "ParameterList(\n",
      "    (0): Parameter containing: [torch.FloatTensor of size 1x32x32]\n",
      "    (1): Parameter containing: [torch.FloatTensor of size 32x48x390]\n",
      "    (2): Parameter containing: [torch.FloatTensor of size 390x48x32]\n",
      "    (3): Parameter containing: [torch.FloatTensor of size 32x32x1]\n",
      ")\n",
      "1203200\n"
     ]
    }
   ],
   "source": [
    "TT_SHAPES = (32, 48, 48, 32)\n",
    "TT_RANKS = [1, 380, 390, 380, 1] # comp rate 0.5\n",
    "SVD_RANKS = 350\n",
    "\n",
    "\n",
    "fc_w = colbert.bert.encoder.layer[3].intermediate.dense\n",
    "fc_b = colbert.bert.encoder.layer[3].intermediate.dense.bias\n",
    "\n",
    "(out_, in_) = fc_w.weight.shape\n",
    "print (out_, in_)\n",
    "factorized_layer = TTLayer(fc_w, shapes = TT_SHAPES, in_dims = [32, 24], ranks = TT_RANKS)\n",
    "print (factorized_layer.cores)\n",
    "print(sum(p.numel() for p in factorized_layer.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072 768\n",
      "ParameterList(\n",
      "    (0): Parameter containing: [torch.FloatTensor of size 1x32x32]\n",
      "    (1): Parameter containing: [torch.FloatTensor of size 32x48x450]\n",
      "    (2): Parameter containing: [torch.FloatTensor of size 450x48x32]\n",
      "    (3): Parameter containing: [torch.FloatTensor of size 32x32x1]\n",
      ")\n",
      "torch.Size([1, 32, 32])\n",
      "torch.Size([32, 48, 450])\n",
      "torch.Size([450, 48, 32])\n",
      "torch.Size([32, 32, 1])\n",
      "3072 768\n",
      "ParameterList(\n",
      "    (0): Parameter containing: [torch.FloatTensor of size 1x32x32]\n",
      "    (1): Parameter containing: [torch.FloatTensor of size 32x48x450]\n",
      "    (2): Parameter containing: [torch.FloatTensor of size 450x48x32]\n",
      "    (3): Parameter containing: [torch.FloatTensor of size 32x32x1]\n",
      ")\n",
      "torch.Size([1, 32, 32])\n",
      "torch.Size([32, 48, 450])\n",
      "torch.Size([450, 48, 32])\n",
      "torch.Size([32, 32, 1])\n",
      "3072 768\n",
      "ParameterList(\n",
      "    (0): Parameter containing: [torch.FloatTensor of size 1x32x32]\n",
      "    (1): Parameter containing: [torch.FloatTensor of size 32x48x450]\n",
      "    (2): Parameter containing: [torch.FloatTensor of size 450x48x32]\n",
      "    (3): Parameter containing: [torch.FloatTensor of size 32x32x1]\n",
      ")\n",
      "torch.Size([1, 32, 32])\n",
      "torch.Size([32, 48, 450])\n",
      "torch.Size([450, 48, 32])\n",
      "torch.Size([32, 32, 1])\n",
      "3072 768\n",
      "ParameterList(\n",
      "    (0): Parameter containing: [torch.FloatTensor of size 1x32x32]\n",
      "    (1): Parameter containing: [torch.FloatTensor of size 32x48x450]\n",
      "    (2): Parameter containing: [torch.FloatTensor of size 450x48x32]\n",
      "    (3): Parameter containing: [torch.FloatTensor of size 32x32x1]\n",
      ")\n",
      "torch.Size([1, 32, 32])\n",
      "torch.Size([32, 48, 450])\n",
      "torch.Size([450, 48, 32])\n",
      "torch.Size([32, 32, 1])\n",
      "3072 768\n",
      "ParameterList(\n",
      "    (0): Parameter containing: [torch.FloatTensor of size 1x32x32]\n",
      "    (1): Parameter containing: [torch.FloatTensor of size 32x48x450]\n",
      "    (2): Parameter containing: [torch.FloatTensor of size 450x48x32]\n",
      "    (3): Parameter containing: [torch.FloatTensor of size 32x32x1]\n",
      ")\n",
      "torch.Size([1, 32, 32])\n",
      "torch.Size([32, 48, 450])\n",
      "torch.Size([450, 48, 32])\n",
      "torch.Size([32, 32, 1])\n",
      "3072 768\n",
      "ParameterList(\n",
      "    (0): Parameter containing: [torch.FloatTensor of size 1x32x32]\n",
      "    (1): Parameter containing: [torch.FloatTensor of size 32x48x450]\n",
      "    (2): Parameter containing: [torch.FloatTensor of size 450x48x32]\n",
      "    (3): Parameter containing: [torch.FloatTensor of size 32x32x1]\n",
      ")\n",
      "torch.Size([1, 32, 32])\n",
      "torch.Size([32, 48, 450])\n",
      "torch.Size([450, 48, 32])\n",
      "torch.Size([32, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "TT_SHAPES = [32, 48, 48, 32]\n",
    "TT_RANKS = [450, 450, 450]\n",
    "\n",
    "for i in [0, 2, 4, 6, 8, 10]:\n",
    "    # fc part\n",
    "    fc_w = colbert.bert.encoder.layer[i].intermediate.dense\n",
    "    fc_b = colbert.bert.encoder.layer[i].intermediate.dense.bias\n",
    "    (out_, in_) = fc_w.weight.shape\n",
    "    print (out_, in_)\n",
    "    factorized_layer = TTLayer(fc_w, shapes = TT_SHAPES, in_dims = [32, 24], ranks = TT_RANKS)\n",
    "    print (factorized_layer.cores)\n",
    "    for elem in factorized_layer.cores:\n",
    "        print (elem.shape)\n",
    "        \n",
    "    colbert.bert.encoder.layer[i].intermediate.dense = factorized_layer\n",
    "            \n",
    "    fc_w = colbert.bert.encoder.layer[i].output.dense\n",
    "    factorized_layer = TTLayer(fc_w, shapes = TT_SHAPES, in_dims = [32, 48, 2], ranks = TT_RANKS)\n",
    "    colbert.bert.encoder.layer[i].output.dense = factorized_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1385216\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in colbert.bert.encoder.layer[2].output.dense.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97882368\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in colbert.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import tntorch as tn\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tensor_train\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "\n",
    "\n",
    "def matrix_to_tt_cores(matrix, shapes, ranks):\n",
    "  shapes = np.asarray(shapes)\n",
    "  matrix = matrix.reshape(list(shapes.flatten()))\n",
    "  print (matrix.shape)\n",
    "  d = len(shapes[0])\n",
    "  transpose_idx = list(np.arange(2 * d).reshape(2, d).T.flatten())\n",
    "  matrix = matrix.permute(*transpose_idx)\n",
    "  print (matrix.shape)\n",
    "  newshape = np.prod(shapes, 0)\n",
    "  matrix = matrix.reshape(list(newshape))\n",
    "  print (matrix.shape)\n",
    "  #tt = tn.Tensor(matrix, ranks_tt=ranks)\n",
    "  tt = tensor_train(full, rank = ranks)\n",
    "\n",
    "\n",
    "\n",
    "  newcores = []\n",
    "  for core, s1, s2, r1, r2 in zip(tt.cores,\n",
    "                                  shapes[0], shapes[1],\n",
    "                                  tt.ranks_tt, tt.ranks_tt[1:]):\n",
    "    newcores.append(core.reshape((r1, s1, s2, r2)))\n",
    "  return newcores\n",
    "\n",
    "\n",
    "def ttmatmul(cores, t, shapes, ranks):\n",
    "  ranks = [1] + ranks + [1]\n",
    "  tshape = t.shape\n",
    "\n",
    "  t = t.transpose(1, 0)\n",
    "  t = t.reshape((-1, shapes[1][-1], 1))\n",
    "  ndims = len(cores)\n",
    "  for i in reversed(range(ndims)):\n",
    "    t = torch.einsum('aijb,rjb->ira', (cores[i], t))\n",
    "    if i:\n",
    "      t = t.reshape((-1, shapes[1][i - 1], ranks[i]))\n",
    "  t = t.reshape((int(np.prod(shapes[0])), tshape[1]))\n",
    "  return t\n",
    "\n",
    "\n",
    "def transpose(cores):\n",
    "    result = []\n",
    "    for c in cores:\n",
    "        result.append(c.permute((0, 2, 1, 3)))\n",
    "    return result\n",
    "\n",
    "\n",
    "def matmultt(t, cores, shapes, ranks):\n",
    "    #t = t.transpose(1, 0)\n",
    "    #cores = transpose(cores)\n",
    "    shapes = [shapes[1], shapes[0]]\n",
    "    return ttmatmul(cores, t, shapes, ranks).transpose(1, 0)\n",
    "\n",
    "\n",
    "class TTLayer(nn.Module):\n",
    "    def __init__(self, layer, ranks):\n",
    "        super(TTLayer, self).__init__()\n",
    "        self.ranks = ranks\n",
    "        with torch.no_grad():\n",
    "            #weight = layer.weight.transpose(1, 0)\n",
    "            self.cores = nn.ParameterList(\n",
    "            map(nn.Parameter, tensor_train(layer, rank = ranks)))\n",
    "        #self.bias = layer.bias\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = matmultt(inputs, self.cores, self.shapes, self.ranks)\n",
    "        out = out + self.bias\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([253, 6, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.rand(11*23, 3*2, 2*3)\n",
    "v = torch.rand(30, 11 * 3 *2)  # Note: batch = 30, 11 * 3 features\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = tensor_train(m, rank = [1, 36, 6, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = [11, 3, 2]\n",
    "output_dims = [23, 2, 3]\n",
    "ranks = [50, 50]\n",
    "\n",
    "ttm = tn.TTMatrix(m, input_dims=input_dims, output_dims=output_dims, ranks=ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  3,  2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttm.input_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TTTensor' object has no attribute 'input_dims'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9718/2754178192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtt_multiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.8.10/lib/python3.8/site-packages/tntorch/matrix.py\u001b[0m in \u001b[0;36mtt_multiply\u001b[0;34m(tt_matrix, tensor)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TTTensor' object has no attribute 'input_dims'"
     ]
    }
   ],
   "source": [
    "a = tn.tt_multiply(tt, v)\n",
    "print (a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 23, 36])\n",
      "torch.Size([36, 3, 2, 6])\n",
      "torch.Size([6, 2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "for elem in ttm.cores:\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 33])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tt_multiply():\n",
    "    m = torch.rand(11 * 3, 23 * 2)\n",
    "    v = torch.rand(30, 11 * 3)  # Note: batch = 30, 11 * 3 features\n",
    "\n",
    "    input_dims = [11, 3]\n",
    "    output_dims = [23, 2]\n",
    "    ranks = [50]\n",
    "\n",
    "    ttm = tn.TTMatrix(m, input_dims=input_dims, output_dims=output_dims, ranks=ranks)\n",
    "    assert torch.allclose(v @ m, tn.tt_multiply(ttm, v))\n",
    "\n",
    "    cpm = tn.CPMatrix(m, input_dims=input_dims, output_dims=output_dims, rank=ranks[0])\n",
    "    assert torch.allclose(v @ m, tn.cp_multiply(cpm, v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_w = colbert.bert.encoder.layer[4].intermediate.dense.weight.data.cpu()\n",
    "fc = colbert.bert.encoder.layer[4].intermediate.dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.8.10/lib/python3.8/site-packages/tensorly/backend/core.py:1106: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    }
   ],
   "source": [
    "new_layer = TTLayer(fc_w.reshape(32, 48, 48, 32), ranks = [1, 380, 390, 380, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n",
      "torch.Size([32, 48, 390])\n",
      "torch.Size([390, 48, 32])\n",
      "torch.Size([32, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "for elem in new_layer.cores:\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_multiply(tt_matrix: TTMatrix, tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Multiply TTMatrix by any tensor of more than 1-way.\n",
    "    For vectors, reshape them to matrix of shape 1 x I\n",
    "    returns: torch.Tensor of shape b x num_cols(tt_matrix)\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(tensor.shape) > 1\n",
    "\n",
    "    rows = torch.prod(tt_matrix.input_dims)\n",
    "    b = tensor.reshape(-1, rows).shape[0]\n",
    "    tensor = tensor.reshape(b, -1).T\n",
    "    result = tensor.reshape(tt_matrix.input_dims[0], -1)\n",
    "    result = torch.einsum('id,lior->ldor', result, tt_matrix.cores[0])\n",
    "\n",
    "    for d in range(1, tt_matrix.d):\n",
    "        result = result.reshape(tt_matrix.input_dims[d], -1, tt_matrix.cores[d].shape[0])\n",
    "        result = torch.einsum('idr,riob->dob', result, tt_matrix.cores[d])\n",
    "\n",
    "    return result.reshape(b, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out_modes = [4, 4, 8, 4, 4]\n",
    "d_in_modes = [2, 4, 8, 4, 2]\n",
    "\n",
    "tt_ranks = [1, 2, 2, 2, 2, 1]\n",
    "tt_ranks2 = [ 1,  1, 16, 54,  6,  1]\n",
    "tt_ranks3 = [1, 4, 4, 4, 4, 1]\n",
    "tt_ranks4 = [1, 2, 4, 4, 2, 1]\n",
    "tt_ranks8 = [1, 2, 4, 8, 4, 2, 1]\n",
    "\n",
    "self.w_1 = ttm.TTLayer(d_in_modes, d_out_modes, tt_ranks3, bias=False)\n",
    "self.w_2 = ttm.TTLayer(d_out_modes,d_in_modes, tt_ranks4, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "new_layer = TTLayer(in_modes = [32, 48, 48, 32], out_modes = [48,32,48, 32], ranks = [1, 380, 390, 380, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18240, 32])\n",
      "torch.Size([12480, 18240])\n",
      "torch.Size([18240, 18720])\n",
      "torch.Size([32, 12160])\n"
     ]
    }
   ],
   "source": [
    "for elem in new_layer.weight:\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.reshape(32, 48, 48, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_w_new.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**singular values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,vh = np.linalg.svd(model.fc1.weight.cpu().detach().numpy())\n",
    "plt.plot(s)\n",
    "print (s[0:1], s[len(s)-2: len(s)-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: (0, 2, 4, 1, 3, 5),\n",
       " 8: (0, 2, 4, 6, 1, 3, 5, 7),\n",
       " 10: (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{6:(0, 2, 4, 1, 3, 5), 8:(0, 2, 4, 6, 1, 3, 5, 7), 10:(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5647360fad83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'input_' is not defined"
     ]
    }
   ],
   "source": [
    "a = colbert.bert.encoder.layer[4].intermediate.dense(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-22e123cdffcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_w_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'input_' is not defined"
     ]
    }
   ],
   "source": [
    "b = fc_w_new(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
