{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import tntorch as tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_multiply_custom(tt: tn.Tensor, vector : torch.Tensor, shapes, in_dims, ranks):\n",
    "    \"\"\"\n",
    "    tensor: bs*768\n",
    "    in_dims = [32, 24]\n",
    "    \"\"\"\n",
    "    bs = vector.shape[0]\n",
    "    seq_len = vector.shape[1]\n",
    "    print (bs, seq_len)\n",
    "    result = vector.reshape(bs*seq_len, in_dims[0], -1)\n",
    "    core = tt.cores[0].reshape(in_dims[0], tt.cores[0].shape[2])\n",
    "    print (result.shape, core.shape)\n",
    "    result = torch.einsum('bid,ir->bdr', result, core)\n",
    "    print (result.shape)\n",
    "    for i in range(1, len(tt.cores)):\n",
    "        if (i < len(in_dims)):\n",
    "            result = result.reshape(-1, in_dims[i], tt.cores[i].shape[0])\n",
    "            core = tt.cores[i].reshape(tt.cores[i].shape[0], in_dims[i], -1, tt.cores[i].shape[2])\n",
    "            print (result.shape, core.shape)\n",
    "            result = torch.einsum('bdr,rdac->bac', result, core)\n",
    "            print (result.shape)\n",
    "        else:\n",
    "            result = result.reshape(bs, -1, tt.cores[i].shape[0])\n",
    "            core = tt.cores[i].reshape(tt.cores[i].shape[0], -1, tt.cores[i].shape[2])\n",
    "            print (result.shape, core.shape)\n",
    "            result = torch.einsum('bdr,rga->bdga', result, core)\n",
    "            print (result.shape)\n",
    "    return result.reshape(bs, seq_len, -1)\n",
    "            \n",
    "    #while (i < len(in_dims)):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 32, 32])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([32, 48, 480])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([480, 48, 32])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([32, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "for elem in tt.cores:\n",
    "    print (type(elem))\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "v = torch.rand(256, 142, 768)\n",
    "m = torch.rand(768, 3072)\n",
    "m_new = m.reshape((32, 48, 48, 32))\n",
    "print (torch.allclose(m, m_new.reshape(768, 3072), atol=1e-05))\n",
    "tt = tn.Tensor(m_new, ranks_tt=[380, 480, 380])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 142, 3072])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(v @ m).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 142\n",
      "torch.Size([36352, 32, 24]) torch.Size([32, 32])\n",
      "torch.Size([36352, 24, 32])\n",
      "torch.Size([36352, 24, 32]) torch.Size([32, 24, 2, 480])\n",
      "torch.Size([36352, 2, 480])\n",
      "torch.Size([256, 284, 480]) torch.Size([480, 48, 32])\n",
      "torch.Size([256, 284, 48, 32])\n",
      "torch.Size([256, 13632, 32]) torch.Size([32, 32, 1])\n",
      "torch.Size([256, 13632, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "res = tt_multiply_custom(tt, v, (32, 48, 48, 32), [32, 24], [1, 3, 4, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([185.2893, 189.9231, 192.0984, 187.3029, 187.7662])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:5, 2, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 3072])\n",
      "torch.Size([256, 142, 3072])\n",
      "torch.Size([256, 142, 3072])\n",
      "tensor([190.8096, 190.1509, 193.0630, 190.5253, 207.3197])\n"
     ]
    }
   ],
   "source": [
    "a = tt.torch().reshape(768, 3072)\n",
    "print (a.shape)\n",
    "print ((v @ a).shape)\n",
    "print (res.shape)\n",
    "print ((v @ a)[:5, 2, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6245e-07)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm((v @ a)- res)/torch.norm(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print (torch.allclose(res, (v @ a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "v = torch.rand(256, 142, 768)\n",
    "m = torch.rand(3072, 768)\n",
    "m_new = m.reshape((32, 48, 48, 32))\n",
    "print (torch.allclose(m, m_new.reshape(3072, 768), atol=1e-05))\n",
    "tt = tn.Tensor(m_new, ranks_tt=[3, 4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 32, 3])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 48, 4])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([4, 48, 3])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "for elem in tt.cores:\n",
    "    print (type(elem))\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 142\n",
      "torch.Size([36352, 32, 24]) torch.Size([32, 3])\n",
      "torch.Size([36352, 24, 3])\n",
      "torch.Size([18176, 48, 3]) torch.Size([3, 48, 1, 4])\n",
      "torch.Size([18176, 1, 4])\n",
      "torch.Size([9088, 2, 4]) torch.Size([4, 2, 24, 3])\n",
      "torch.Size([9088, 24, 3])\n",
      "torch.Size([256, 852, 3]) torch.Size([3, 32, 1])\n",
      "torch.Size([256, 852, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "res = tt_multiply_custom(tt, v, (32, 48, 48, 32), [32, 48, 2], [1, 3, 4, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 768])\n",
      "tensor([780.9492, 773.5886, 772.0028, 771.8756, 772.8912])\n"
     ]
    }
   ],
   "source": [
    "a = tt.torch().reshape(3072, 768)\n",
    "print (a.shape)\n",
    "print ((v @ a)[:5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([780.9583, 773.3998, 771.8484, 771.7330, 772.8489])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print (torch.allclose(res, (v @ a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm((v @ a)- res)/torch.norm(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(m, m_new.reshape(3072, 768), atol=1e-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regular tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "v = torch.rand(30, 768)\n",
    "m = torch.rand(768, 3072)\n",
    "m_new = m.reshape((32, 24, 64, 48))\n",
    "print (torch.allclose(m, m_new.reshape(768, 3072), atol=1e-05))\n",
    "tt = tn.Tensor(m_new, ranks_tt=[3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "torch.Size([30, 32, 24]) torch.Size([32, 3])\n",
      "torch.Size([30, 24, 3])\n",
      "torch.Size([30, 24, 3]) torch.Size([3, 24, 1, 4])\n",
      "torch.Size([30, 1, 4])\n",
      "torch.Size([30, 1, 4]) torch.Size([4, 64, 5])\n",
      "torch.Size([30, 1, 64, 5])\n",
      "torch.Size([30, 64, 5]) torch.Size([5, 48, 1])\n",
      "torch.Size([30, 64, 48, 1])\n"
     ]
    }
   ],
   "source": [
    "res = tt_multiply_custom(tt, v, (32, 24, 64, 48), [32, 24], [1, 3, 4, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 3072])\n",
      "tensor([187.1352, 195.8420, 189.3099, 190.3286, 191.1834])\n"
     ]
    }
   ],
   "source": [
    "a = tt.torch().reshape(768, 3072)\n",
    "print (a.shape)\n",
    "print ((v @ a)[:5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([187.1352, 195.8420, 189.3099, 190.3287, 191.1834])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose((v @ a), res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**singular values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: (0, 2, 4, 1, 3, 5),\n",
       " 8: (0, 2, 4, 6, 1, 3, 5, 7),\n",
       " 10: (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{6:(0, 2, 4, 1, 3, 5), 8:(0, 2, 4, 6, 1, 3, 5, 7), 10:(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5647360fad83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'input_' is not defined"
     ]
    }
   ],
   "source": [
    "a = colbert.bert.encoder.layer[4].intermediate.dense(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-22e123cdffcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_w_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'input_' is not defined"
     ]
    }
   ],
   "source": [
    "b = fc_w_new(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorly.tt_matrix import TTMatrix\n",
    "\n",
    "perms = {6:(0, 2, 4, 1, 3, 5), 8:(0, 2, 4, 6, 1, 3, 5, 7), 10:(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)}\n",
    "\n",
    "for rank in [ 20, 30, 40, 50]:\n",
    "    m = colbert.bert.encoder.layer[4].intermediate.dense\n",
    "    input_ = torch.randn(batch_size, in_)\n",
    "    m_ttm = FactorizationTTMLinear(in_, out_, rank=rank, max_core_dim_product =rank)\n",
    "    m_ttm.fill_with_pretrained_matrix(fc_w)\n",
    "    restored_weight = TTMatrix([elem.data for elem in m_ttm.ttm.tt.cores]).to_tensor()\n",
    "    print (restored_weight.shape)\n",
    "    restored_weight = restored_weight.permute(perms[(len(restored_weight.shape))])\n",
    "    print (restored_weight.shape)\n",
    "    print (torch.norm(fc_w_new.weight - restored_weight.reshape(fc_w_new.weight.shape))/torch.norm(fc_w_new.weight))\n",
    "    print (restored_weight.shape)\n",
    "    c = m_ttm(input_)\n",
    "    print (torch.norm(a-c)/torch.norm(a))\n",
    "    print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(771.9188, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(a-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor_train_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-993f0028478e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_train_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor_train_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "factors = tensor_train_matrix(B, rank = [1, 60, 90, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 16, 60])\n",
      "torch.Size([60, 12, 12, 90])\n",
      "torch.Size([90, 8, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "for elem in factors.factors:\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 12, 8, 12, 16])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_B = factors.to_tensor()\n",
    "new_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 12, 8, 12, 16])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70110387"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(new_B - B)/np.linalg.norm(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 8, 60])\n",
      "torch.Size([60, 16, 12, 90])\n",
      "torch.Size([90, 12, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "for elem in factors:\n",
    "    print (elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 3072)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_w.shape[1],fc_w.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ttm_linear.ttm_linear.ttm_linear import FactorizationTTMLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 48, 48, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs2 = []\n",
    "ranks2 = []\n",
    "c_rates2 = []\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tensor_train\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "\n",
    "B = fc_w\n",
    "B = B.reshape((32, 48, 48, 32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "err = 10.0\n",
    "rank1 = 5\n",
    "rank2 = 5\n",
    "step = 10\n",
    "compression_rate = 0.0\n",
    "while (compression_rate < 0.7):\n",
    "    factors = tensor_train(B, rank = [1, rank1, rank2, rank1, 1])\n",
    "    new_B = factors.to_tensor()\n",
    "    err = np.linalg.norm(new_B.detach().numpy() - B.detach().numpy())/np.linalg.norm(B.detach().numpy())\n",
    "    print ([elem.shape for elem in factors.factors])\n",
    "    compression_rate = (np.sum(list(np.prod(elem.shape) for elem in factors.factors))/(np.prod(fc_w.shape)))\n",
    "    print (\"err \", err, \"compression_rate \", compression_rate, \"rank \", rank1, rank2)\n",
    "    errs2.append(err)\n",
    "    ranks2.append(rank1)\n",
    "    c_rates2.append(compression_rate)\n",
    "    if (rank1 < rank2):\n",
    "        rank1 += step\n",
    "    else:\n",
    "        rank2 += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 128, 5]), torch.Size([5, 144, 5]), torch.Size([5, 128, 1])]\n",
      "err  0.9830911 compression_rate  0.002068413628472222 rank  5 5\n",
      "[torch.Size([1, 128, 5]), torch.Size([5, 144, 15]), torch.Size([15, 128, 1])]\n",
      "err  0.97657156 compression_rate  0.005662706163194444 rank  5 15\n",
      "[torch.Size([1, 128, 15]), torch.Size([15, 144, 15]), torch.Size([15, 128, 1])]\n",
      "err  0.9700918 compression_rate  0.015360514322916666 rank  15 15\n",
      "[torch.Size([1, 128, 15]), torch.Size([15, 144, 25]), torch.Size([25, 128, 1])]\n",
      "err  0.96239424 compression_rate  0.025058322482638888 rank  15 25\n",
      "[torch.Size([1, 128, 25]), torch.Size([25, 144, 25]), torch.Size([25, 128, 1])]\n",
      "err  0.9518059 compression_rate  0.04085964626736111 rank  25 25\n",
      "[torch.Size([1, 128, 25]), torch.Size([25, 144, 35]), torch.Size([35, 128, 1])]\n",
      "err  0.94061637 compression_rate  0.056660970052083336 rank  25 35\n",
      "[torch.Size([1, 128, 35]), torch.Size([35, 144, 35]), torch.Size([35, 128, 1])]\n",
      "err  0.92628205 compression_rate  0.07856580946180555 rank  35 35\n",
      "[torch.Size([1, 128, 35]), torch.Size([35, 144, 45]), torch.Size([45, 128, 1])]\n",
      "err  0.91174954 compression_rate  0.10047064887152778 rank  35 45\n",
      "[torch.Size([1, 128, 45]), torch.Size([45, 144, 45]), torch.Size([45, 128, 1])]\n",
      "err  0.89364284 compression_rate  0.12847900390625 rank  45 45\n",
      "[torch.Size([1, 128, 45]), torch.Size([45, 144, 55]), torch.Size([55, 128, 1])]\n",
      "err  0.8757278 compression_rate  0.1564873589409722 rank  45 55\n",
      "[torch.Size([1, 128, 55]), torch.Size([55, 144, 55]), torch.Size([55, 128, 1])]\n",
      "err  0.8540543 compression_rate  0.19059922960069445 rank  55 55\n",
      "[torch.Size([1, 128, 55]), torch.Size([55, 144, 65]), torch.Size([65, 128, 1])]\n",
      "err  0.832709 compression_rate  0.22471110026041666 rank  55 65\n",
      "[torch.Size([1, 128, 65]), torch.Size([65, 144, 65]), torch.Size([65, 128, 1])]\n",
      "err  0.8069761 compression_rate  0.2649264865451389 rank  65 65\n",
      "[torch.Size([1, 128, 65]), torch.Size([65, 144, 75]), torch.Size([75, 128, 1])]\n",
      "err  0.7816111 compression_rate  0.3051418728298611 rank  65 75\n",
      "[torch.Size([1, 128, 75]), torch.Size([75, 144, 75]), torch.Size([75, 128, 1])]\n",
      "err  0.7513101 compression_rate  0.3514607747395833 rank  75 75\n",
      "[torch.Size([1, 128, 75]), torch.Size([75, 144, 85]), torch.Size([85, 128, 1])]\n",
      "err  0.72151625 compression_rate  0.3977796766493056 rank  75 85\n",
      "[torch.Size([1, 128, 85]), torch.Size([85, 144, 85]), torch.Size([85, 128, 1])]\n",
      "err  0.6855759 compression_rate  0.4502020941840278 rank  85 85\n",
      "[torch.Size([1, 128, 85]), torch.Size([85, 144, 95]), torch.Size([95, 128, 1])]\n",
      "err  0.6503146 compression_rate  0.50262451171875 rank  85 95\n",
      "[torch.Size([1, 128, 95]), torch.Size([95, 144, 95]), torch.Size([95, 128, 1])]\n",
      "err  0.60742176 compression_rate  0.5611504448784722 rank  95 95\n",
      "[torch.Size([1, 128, 95]), torch.Size([95, 144, 105]), torch.Size([105, 128, 1])]\n",
      "err  0.5646886 compression_rate  0.6196763780381944 rank  95 105\n",
      "[torch.Size([1, 128, 105]), torch.Size([105, 144, 105]), torch.Size([105, 128, 1])]\n",
      "err  0.51182956 compression_rate  0.6843058268229166 rank  105 105\n",
      "[torch.Size([1, 128, 105]), torch.Size([105, 144, 115]), torch.Size([115, 128, 1])]\n",
      "err  0.45775306 compression_rate  0.7489352756076388 rank  105 115\n"
     ]
    }
   ],
   "source": [
    "errs3 = []\n",
    "ranks3 = []\n",
    "c_rates3 = []\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tensor_train\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "\n",
    "B = fc_w\n",
    "B = B.reshape(128, 144, 128)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "err = 10.0\n",
    "rank1 = 5\n",
    "rank2 = 5\n",
    "step = 10\n",
    "compression_rate = 0.0\n",
    "while (compression_rate < 0.7):\n",
    "    factors = tensor_train(B, rank = [1, rank1, rank2, 1])\n",
    "    new_B = factors.to_tensor()\n",
    "    err = np.linalg.norm(new_B.detach().numpy() - B.detach().numpy())/np.linalg.norm(B.detach().numpy())\n",
    "    print ([elem.shape for elem in factors.factors])\n",
    "    compression_rate = (np.sum(list(np.prod(elem.shape) for elem in factors.factors))/(np.prod(fc_w.shape)))\n",
    "    print (\"err \", err, \"compression_rate \", compression_rate, \"rank \", rank1, rank2)\n",
    "    errs3.append(err)\n",
    "    ranks3.append(rank1)\n",
    "    c_rates3.append(compression_rate)\n",
    "    if (rank1 < rank2):\n",
    "        rank1 += step\n",
    "    else:\n",
    "        rank2 += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c_rates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_180/2976066177.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SVD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_rates3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrs3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TT 3 cores, 128*144*128 \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_rates3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrs3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TT 4 cores, 32*48*48*32 \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c_rates' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "\n",
    "# plot lines\n",
    "plt.plot(c_rates, errs, label = \"SVD\")\n",
    "plt.plot(c_rates3, errs3,  label = \"TT 3 cores, 128*144*128 \")\n",
    "plt.plot(c_rates3, errs3,  label = \"TT 4 cores, 32*48*48*32 \")\n",
    "plt.plot(c_rates1, errs1,  label = \"TT 6 cores, 8*12*16*16*12*8\")\n",
    "#plt.plot(errs1_m, c_rates1_m, label = \"TTM (permute + reshape)\")\n",
    "plt.ylabel('errors')\n",
    "plt.xlabel('compression rate')\n",
    "plt.legend()\n",
    "plt.savefig(\"TT + SVD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 335]), torch.Size([335, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5942937 compression_rate  0.4440646701388889 rank  335 335\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 345]), torch.Size([345, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5857147 compression_rate  0.4570855034722222 rank  335 345\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 345]), torch.Size([345, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5857147 compression_rate  0.4570855034722222 rank  345 345\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 355]), torch.Size([355, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5772192 compression_rate  0.4701063368055556 rank  345 355\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 355]), torch.Size([355, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5772191 compression_rate  0.4701063368055556 rank  355 355\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 365]), torch.Size([365, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5688087 compression_rate  0.4831271701388889 rank  355 365\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 365]), torch.Size([365, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5688087 compression_rate  0.4831271701388889 rank  365 365\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 375]), torch.Size([375, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.56046605 compression_rate  0.4961480034722222 rank  365 375\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 375]), torch.Size([375, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5604661 compression_rate  0.4961480034722222 rank  375 375\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 385]), torch.Size([385, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5522069 compression_rate  0.5091688368055556 rank  375 385\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 385]), torch.Size([385, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5522069 compression_rate  0.5091688368055556 rank  385 385\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 395]), torch.Size([395, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5440476 compression_rate  0.5221896701388888 rank  385 395\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 395]), torch.Size([395, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.54404753 compression_rate  0.5221896701388888 rank  395 395\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 405]), torch.Size([405, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5359411 compression_rate  0.5352105034722222 rank  395 405\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 405]), torch.Size([405, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.53594106 compression_rate  0.5352105034722222 rank  405 405\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 415]), torch.Size([415, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5279132 compression_rate  0.5482313368055556 rank  405 415\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 415]), torch.Size([415, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.5279132 compression_rate  0.5482313368055556 rank  415 415\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 425]), torch.Size([425, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.51994663 compression_rate  0.5612521701388888 rank  415 425\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 425]), torch.Size([425, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.51994663 compression_rate  0.5612521701388888 rank  425 425\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 435]), torch.Size([435, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.51204914 compression_rate  0.5742730034722222 rank  425 435\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 435]), torch.Size([435, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.512049 compression_rate  0.5742730034722222 rank  435 435\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 445]), torch.Size([445, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.50423944 compression_rate  0.5872938368055556 rank  435 445\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 445]), torch.Size([445, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.50423944 compression_rate  0.5872938368055556 rank  445 445\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 455]), torch.Size([455, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.49648055 compression_rate  0.6003146701388888 rank  445 455\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 455]), torch.Size([455, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.49648046 compression_rate  0.6003146701388888 rank  455 455\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 465]), torch.Size([465, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.48879352 compression_rate  0.6133355034722222 rank  455 465\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 465]), torch.Size([465, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.48879352 compression_rate  0.6133355034722222 rank  465 465\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 475]), torch.Size([475, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.48117173 compression_rate  0.6263563368055556 rank  465 475\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 475]), torch.Size([475, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.4811717 compression_rate  0.6263563368055556 rank  475 475\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 485]), torch.Size([485, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.4736112 compression_rate  0.6393771701388888 rank  475 485\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 485]), torch.Size([485, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.47361115 compression_rate  0.6393771701388888 rank  485 485\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 495]), torch.Size([495, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.4661179 compression_rate  0.6523980034722222 rank  485 495\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 495]), torch.Size([495, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.46611792 compression_rate  0.6523980034722222 rank  495 495\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 505]), torch.Size([505, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.45867184 compression_rate  0.6654188368055556 rank  495 505\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 505]), torch.Size([505, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.45867184 compression_rate  0.6654188368055556 rank  505 505\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 515]), torch.Size([515, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.45130017 compression_rate  0.6784396701388888 rank  505 515\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 515]), torch.Size([515, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.45130017 compression_rate  0.6784396701388888 rank  515 515\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 525]), torch.Size([525, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.44399664 compression_rate  0.6914605034722222 rank  515 525\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 525]), torch.Size([525, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.4439966 compression_rate  0.6914605034722222 rank  525 525\n",
      "[torch.Size([1, 8, 8]), torch.Size([8, 12, 96]), torch.Size([96, 16, 535]), torch.Size([535, 16, 96]), torch.Size([96, 12, 8]), torch.Size([8, 8, 1])]\n",
      "err  0.4367761 compression_rate  0.7044813368055556 rank  525 535\n"
     ]
    }
   ],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.decomposition import tensor_train\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "errs1 = []\n",
    "ranks1 = []\n",
    "c_rates1 = []\n",
    "\n",
    "B = fc_w\n",
    "B = B.reshape(8, 12, 16, 16, 12, 8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "err = 10.0\n",
    "rank1 = 5\n",
    "rank2 = 5\n",
    "step = 10\n",
    "compression_rate = 0.0\n",
    "while (compression_rate < 0.7):\n",
    "    factors = tensor_train(B, rank = [1, rank1, rank2, rank2, rank2, rank1, 1])\n",
    "    new_B = factors.to_tensor()\n",
    "    err = np.linalg.norm(new_B.detach().numpy() - B.detach().numpy())/np.linalg.norm(B.detach().numpy())\n",
    "    print ([elem.shape for elem in factors.factors])\n",
    "    compression_rate = (np.sum(list(np.prod(elem.shape) for elem in factors.factors))/(np.prod(fc_w.shape)))\n",
    "    print (\"err \", err, \"compression_rate \", compression_rate, \"rank \", rank1, rank2)\n",
    "    errs1.append(err)\n",
    "    ranks1.append(rank1)\n",
    "    c_rates1.append(compression_rate)\n",
    "    if (rank1 < rank2):\n",
    "        rank1 += step\n",
    "    else:\n",
    "        rank2 += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = fc_w\n",
    "B = B.reshape((32, 48, 48, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359296"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(fc_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81661785"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_rest = tl.tt_tensor.tt_to_tensor(factors)\n",
    "err = np.linalg.norm(D_rest - D)/np.linalg.norm(D)\n",
    "err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
